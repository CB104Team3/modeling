{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# datasets_path = os.path.join('..', 'datasets')\n",
    "path = 'mongo.comment.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+------+\n",
      "|         _c0|           _c1|   _c2|\n",
      "+------------+--------------+------+\n",
      "|    authorID|          name|rating|\n",
      "|        joam|        添好運|    40|\n",
      "|        Nash|        村子口|    35|\n",
      "|      yu0226|    維記茶餐廳|    30|\n",
      "|ipeen1199276|鼎泰豐(信義店)|    40|\n",
      "|      nj1314|    香港茶水攤|    35|\n",
      "|   eggface45|      天下三絕|    50|\n",
      "|   wang12177|        添好運|    40|\n",
      "|      yu0226|        村子口|    35|\n",
      "|mandelicious|    永康牛肉麵|    35|\n",
      "|ipeen1313278|    維記茶餐廳|    30|\n",
      "| ipeen365625|    香港茶水攤|    50|\n",
      "|    BSponpon|鼎泰豐(信義店)|    40|\n",
      "|   hobandnob|      天下三絕|    40|\n",
      "|mjstrong2002|        點點心|    35|\n",
      "|ipeen1208434|      藍家割包|    45|\n",
      "| leesunny989|  杭州小籠湯包|    25|\n",
      "| ipeen572314|        添好運|    40|\n",
      "|mandelicious|      宋廚菜館|    25|\n",
      "|mandelicious|        鼎泰豐|    45|\n",
      "+------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "179455"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import trim, col\n",
    "\n",
    "# from pyspark.ml.tuning import TrainValidateSplit, ParamGridBuilder\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import monotonically_increasing_id \n",
    "\n",
    "df = sqlContext.read.csv(path, header=False) # requires spark 2.0\n",
    "df.show()\n",
    "df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+------+\n",
      "|         _c0|           _c1|   _c2|\n",
      "+------------+--------------+------+\n",
      "|    authorID|          name|rating|\n",
      "|        joam|        添好運|    40|\n",
      "|        Nash|        村子口|    35|\n",
      "|      yu0226|    維記茶餐廳|    30|\n",
      "|ipeen1199276|鼎泰豐(信義店)|    40|\n",
      "|      nj1314|    香港茶水攤|    35|\n",
      "|   eggface45|      天下三絕|    50|\n",
      "|   wang12177|        添好運|    40|\n",
      "|      yu0226|        村子口|    35|\n",
      "|mandelicious|    永康牛肉麵|    35|\n",
      "|ipeen1313278|    維記茶餐廳|    30|\n",
      "| ipeen365625|    香港茶水攤|    50|\n",
      "|    BSponpon|鼎泰豐(信義店)|    40|\n",
      "|   hobandnob|      天下三絕|    40|\n",
      "|mjstrong2002|        點點心|    35|\n",
      "|ipeen1208434|      藍家割包|    45|\n",
      "| leesunny989|  杭州小籠湯包|    25|\n",
      "| ipeen572314|        添好運|    40|\n",
      "|mandelicious|      宋廚菜館|    25|\n",
      "|mandelicious|        鼎泰豐|    45|\n",
      "+------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import trim\n",
    "\n",
    "df = df.withColumn(\"_c0\", trim(df._c0))\n",
    "df = df.withColumn(\"_c1\", trim(df._c1))\n",
    "df = df.withColumn(\"_c2\", trim(df._c2))\n",
    "    \n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|shopid|              name|\n",
      "+------+------------------+\n",
      "|     1|            村子口|\n",
      "|     2|        香港茶水攤|\n",
      "|     3|        雙月食品社|\n",
      "|     4|            添好運|\n",
      "|     5|叁和院(忠孝旗艦店)|\n",
      "|     6|    富霸王豬腳極品|\n",
      "|     7|          龍都酒樓|\n",
      "|     8|        永康牛肉麵|\n",
      "|     9|        維記茶餐廳|\n",
      "|    10|    鼎泰豐(信義店)|\n",
      "|    11|            點點心|\n",
      "|    12|          藍家割包|\n",
      "|    13|      杭州小籠湯包|\n",
      "|    14|    水舞饌(大直店)|\n",
      "|    15|餡老滿(南港旗艦店)|\n",
      "|    16|    牛店精燉牛肉麵|\n",
      "|    17|        新港茶餐廳|\n",
      "|    18|          天下三絕|\n",
      "|    19|          宋廚菜館|\n",
      "|    20|            鼎泰豐|\n",
      "+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33253"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read mysql_shop\n",
    "df_shop = sqlContext.read.csv(\"mysql_shop.csv\", header=True) # requires spark 2.0\n",
    "df_shop = df_shop.withColumnRenamed(\"id\", \"shopid\")\n",
    "df_shop.show()\n",
    "df_shop.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|shopid|              name|\n",
      "+------+------------------+\n",
      "|     1|            村子口|\n",
      "|     2|        香港茶水攤|\n",
      "|     3|        雙月食品社|\n",
      "|     4|            添好運|\n",
      "|     5|叁和院(忠孝旗艦店)|\n",
      "|     6|    富霸王豬腳極品|\n",
      "|     7|          龍都酒樓|\n",
      "|     8|        永康牛肉麵|\n",
      "|     9|        維記茶餐廳|\n",
      "|    10|    鼎泰豐(信義店)|\n",
      "|    11|            點點心|\n",
      "|    12|          藍家割包|\n",
      "|    13|      杭州小籠湯包|\n",
      "|    14|    水舞饌(大直店)|\n",
      "|    15|餡老滿(南港旗艦店)|\n",
      "|    16|    牛店精燉牛肉麵|\n",
      "|    17|        新港茶餐廳|\n",
      "|    18|          天下三絕|\n",
      "|    19|          宋廚菜館|\n",
      "|    20|            鼎泰豐|\n",
      "+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_shop = df_shop.withColumn(\"shopid\", trim(df_shop.shopid))\n",
    "df_shop = df_shop.withColumn(\"name\", trim(df_shop.name))\n",
    "\n",
    "df_shop.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+\n",
      "|commid|    commentator|\n",
      "+------+---------------+\n",
      "|     1|     吃比瘦有福|\n",
      "|     2| Nash，神之領域|\n",
      "|     3|           張小|\n",
      "|     4|         快樂瑜|\n",
      "|     5|         Choco♥|\n",
      "|     6|     蛋寶趴趴go|\n",
      "|     7|         王小玉|\n",
      "|     8|       胖樺饌食|\n",
      "|     9|大胖&小胖吃胖胖|\n",
      "|    10|     SweetBunny|\n",
      "|    11|      Lucy Chen|\n",
      "|    12|   Angela's日嚐|\n",
      "|    13|         饅頭弟|\n",
      "|    14|     強強火車頭|\n",
      "|    15|    sunny(晴兒)|\n",
      "|    16|       summer47|\n",
      "|    17|  Greta饗食趣樂|\n",
      "|    18|     可愛小猴子|\n",
      "|    19| 阿君的玩食天堂|\n",
      "|    20|        寶寶750|\n",
      "+------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17071"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read mysql_commentator\n",
    "df_comm = sqlContext.read.csv(\"mysql_commentator.csv\", header=True) # requires spark 2.0\n",
    "df_comm = df_comm.withColumnRenamed(\"id\", \"commid\")\n",
    "df_comm.show()\n",
    "df_comm.count()\n",
    "# df_comm.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+\n",
      "|commid|    commentator|\n",
      "+------+---------------+\n",
      "|     1|     吃比瘦有福|\n",
      "|     2| Nash，神之領域|\n",
      "|     3|           張小|\n",
      "|     4|         快樂瑜|\n",
      "|     5|         Choco♥|\n",
      "|     6|     蛋寶趴趴go|\n",
      "|     7|         王小玉|\n",
      "|     8|       胖樺饌食|\n",
      "|     9|大胖&小胖吃胖胖|\n",
      "|    10|     SweetBunny|\n",
      "|    11|      Lucy Chen|\n",
      "|    12|   Angela's日嚐|\n",
      "|    13|         饅頭弟|\n",
      "|    14|     強強火車頭|\n",
      "|    15|    sunny(晴兒)|\n",
      "|    16|       summer47|\n",
      "|    17|  Greta饗食趣樂|\n",
      "|    18|     可愛小猴子|\n",
      "|    19| 阿君的玩食天堂|\n",
      "|    20|        寶寶750|\n",
      "+------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_comm = df_comm.withColumn(\"commid\", trim(df_comm.commid))\n",
    "df_comm = df_comm.withColumn(\"commentator\", trim(df_comm.commentator))\n",
    "df_comm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------------+---+------+-----------+\n",
      "|       _c0|                       _c1|_c2|commid|commentator|\n",
      "+----------+--------------------------+---+------+-----------+\n",
      "|   kayfire|              穆記牛肉麵館| 15|   979|    kayfire|\n",
      "|    simona|                    秦味館| 50|   687|     simona|\n",
      "|  nightoro|                紅磡新飲茶| 25|   714|   nightoro|\n",
      "|    yuning|            鼎泰豐(信義店)| 50|    72|     yuning|\n",
      "|  JosefLee|                  銀翼餐廳| 45|  1459|   JosefLee|\n",
      "|  luckbear|                    意麵王| 30|   130|   luckbear|\n",
      "|    calamy|           六福客棧-金鳳廳| 35|   530|     calamy|\n",
      "|    seagod|              劉山東牛肉麵| 35|   600|     seagod|\n",
      "|  andy4990|        海霸王餐廳(中山店)| 35|   712|   andy4990|\n",
      "|  nightoro|                開飯川食堂| 30|   714|   nightoro|\n",
      "|   lun1203|          牛軋堂牛肉麵本家| 40|   734|    lun1203|\n",
      "|  Naizigie|         南港 北大荒水餃店| 35|   739|   Naizigie|\n",
      "|     Feena|                天雲扁食店| 35|  1122|      Feena|\n",
      "|      1000|            香港波記茶餐廳| 35|  1127|       1000|\n",
      "|sharonliao|              吉星港式飲茶| 40|  1126| sharonliao|\n",
      "|  luckbear|                好記擔仔麵| 35|   130|   luckbear|\n",
      "|     venny|三元喜事豬腳專賣店(商城店)| 35|   362|      venny|\n",
      "| amy803131|                天雲扁食店| 25|  1140|  amy803131|\n",
      "| AnnaQueen|            香港波記茶餐廳| 30|  1141|  AnnaQueen|\n",
      "|    calamy|           六福客棧-金鳳廳| 40|   530|     calamy|\n",
      "+----------+--------------------------+---+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8301"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cr = df.join(df_comm, df._c0 == df_comm.commentator, \"inner\")\n",
    "df_cr.show()\n",
    "df_cr.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------------+---+------+-----------+------+--------------------------+\n",
      "|       _c0|                       _c1|_c2|commid|commentator|shopid|                      name|\n",
      "+----------+--------------------------+---+------+-----------+------+--------------------------+\n",
      "|   kayfire|              穆記牛肉麵館| 15|   979|    kayfire|    34|              穆記牛肉麵館|\n",
      "|    simona|                    秦味館| 50|   687|     simona|    23|                    秦味館|\n",
      "|  nightoro|                紅磡新飲茶| 25|   714|   nightoro|    82|                紅磡新飲茶|\n",
      "|    yuning|            鼎泰豐(信義店)| 50|    72|     yuning|    10|            鼎泰豐(信義店)|\n",
      "|  JosefLee|                  銀翼餐廳| 45|  1459|   JosefLee|   101|                  銀翼餐廳|\n",
      "|  luckbear|                    意麵王| 30|   130|   luckbear|   106|                    意麵王|\n",
      "|    calamy|           六福客棧-金鳳廳| 35|   530|     calamy|   100|           六福客棧-金鳳廳|\n",
      "|    seagod|              劉山東牛肉麵| 35|   600|     seagod|    32|              劉山東牛肉麵|\n",
      "|  andy4990|        海霸王餐廳(中山店)| 35|   712|   andy4990|    47|        海霸王餐廳(中山店)|\n",
      "|  nightoro|                開飯川食堂| 30|   714|   nightoro|    48|                開飯川食堂|\n",
      "|   lun1203|          牛軋堂牛肉麵本家| 40|   734|    lun1203|    25|          牛軋堂牛肉麵本家|\n",
      "|  Naizigie|         南港 北大荒水餃店| 35|   739|   Naizigie|    52|         南港 北大荒水餃店|\n",
      "|     Feena|                天雲扁食店| 35|  1122|      Feena|    69|                天雲扁食店|\n",
      "|      1000|            香港波記茶餐廳| 35|  1127|       1000|    66|            香港波記茶餐廳|\n",
      "|sharonliao|              吉星港式飲茶| 40|  1126| sharonliao|    64|              吉星港式飲茶|\n",
      "|  luckbear|                好記擔仔麵| 35|   130|   luckbear|    81|                好記擔仔麵|\n",
      "|     venny|三元喜事豬腳專賣店(商城店)| 35|   362|      venny|    78|三元喜事豬腳專賣店(商城店)|\n",
      "| amy803131|                天雲扁食店| 25|  1140|  amy803131|    69|                天雲扁食店|\n",
      "| AnnaQueen|            香港波記茶餐廳| 30|  1141|  AnnaQueen|    66|            香港波記茶餐廳|\n",
      "|    calamy|           六福客棧-金鳳廳| 40|   530|     calamy|   100|           六福客棧-金鳳廳|\n",
      "+----------+--------------------------+---+------+-----------+------+--------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8285"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cr = df_cr.join(df_shop, df_cr._c1 == df_shop.name, \"inner\")\n",
    "df_cr.show()\n",
    "df_cr.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------------+---+------+-----------+------+--------------------------+\n",
      "|       _c0|                       _c1|_c2|commid|commentator|shopid|                      name|\n",
      "+----------+--------------------------+---+------+-----------+------+--------------------------+\n",
      "|   kayfire|              穆記牛肉麵館| 15|   979|    kayfire|    34|              穆記牛肉麵館|\n",
      "|    simona|                    秦味館| 50|   687|     simona|    23|                    秦味館|\n",
      "|  nightoro|                紅磡新飲茶| 25|   714|   nightoro|    82|                紅磡新飲茶|\n",
      "|    yuning|            鼎泰豐(信義店)| 50|    72|     yuning|    10|            鼎泰豐(信義店)|\n",
      "|  JosefLee|                  銀翼餐廳| 45|  1459|   JosefLee|   101|                  銀翼餐廳|\n",
      "|  luckbear|                    意麵王| 30|   130|   luckbear|   106|                    意麵王|\n",
      "|    calamy|           六福客棧-金鳳廳| 35|   530|     calamy|   100|           六福客棧-金鳳廳|\n",
      "|    seagod|              劉山東牛肉麵| 35|   600|     seagod|    32|              劉山東牛肉麵|\n",
      "|  andy4990|        海霸王餐廳(中山店)| 35|   712|   andy4990|    47|        海霸王餐廳(中山店)|\n",
      "|  nightoro|                開飯川食堂| 30|   714|   nightoro|    48|                開飯川食堂|\n",
      "|   lun1203|          牛軋堂牛肉麵本家| 40|   734|    lun1203|    25|          牛軋堂牛肉麵本家|\n",
      "|  Naizigie|         南港 北大荒水餃店| 35|   739|   Naizigie|    52|         南港 北大荒水餃店|\n",
      "|     Feena|                天雲扁食店| 35|  1122|      Feena|    69|                天雲扁食店|\n",
      "|      1000|            香港波記茶餐廳| 35|  1127|       1000|    66|            香港波記茶餐廳|\n",
      "|sharonliao|              吉星港式飲茶| 40|  1126| sharonliao|    64|              吉星港式飲茶|\n",
      "|  luckbear|                好記擔仔麵| 35|   130|   luckbear|    81|                好記擔仔麵|\n",
      "|     venny|三元喜事豬腳專賣店(商城店)| 35|   362|      venny|    78|三元喜事豬腳專賣店(商城店)|\n",
      "| amy803131|                天雲扁食店| 25|  1140|  amy803131|    69|                天雲扁食店|\n",
      "| AnnaQueen|            香港波記茶餐廳| 30|  1141|  AnnaQueen|    66|            香港波記茶餐廳|\n",
      "|    calamy|           六福客棧-金鳳廳| 40|   530|     calamy|   100|           六福客棧-金鳳廳|\n",
      "+----------+--------------------------+---+------+-----------+------+--------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert cid, rid, _c2 columns to Long\n",
    "\n",
    "import pyspark.sql.types\n",
    "\n",
    "FEATURES_COL = ['commid', 'shopid', '_c2']\n",
    "\n",
    "# print(df_als.columns)\n",
    "for col in df_cr.columns:\n",
    "    if col in FEATURES_COL:\n",
    "        df_cr = df_cr.withColumn(col,df_cr[col].cast('long'))\n",
    "df_cr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+\n",
      "|commid|shopid|_c2|\n",
      "+------+------+---+\n",
      "|   979|    34| 15|\n",
      "|   687|    23| 50|\n",
      "|   714|    82| 25|\n",
      "|    72|    10| 50|\n",
      "|  1459|   101| 45|\n",
      "|   130|   106| 30|\n",
      "|   530|   100| 35|\n",
      "|   600|    32| 35|\n",
      "|   712|    47| 35|\n",
      "|   714|    48| 30|\n",
      "|   734|    25| 40|\n",
      "|   739|    52| 35|\n",
      "|  1122|    69| 35|\n",
      "|  1127|    66| 35|\n",
      "|  1126|    64| 40|\n",
      "|   130|    81| 35|\n",
      "|   362|    78| 35|\n",
      "|  1140|    69| 25|\n",
      "|  1141|    66| 30|\n",
      "|   530|   100| 40|\n",
      "+------+------+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- commid: long (nullable = true)\n",
      " |-- shopid: long (nullable = true)\n",
      " |-- _c2: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_als = df_cr.select('commid', 'shopid', '_c2')\n",
    "df_als.show()\n",
    "df_als.printSchema()\n",
    "\n",
    "# df_als.filter(\"cid = 0\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_als = df_als.withColumnRenamed(\"commid\", \"user\")\n",
    "df_als = df_als.withColumnRenamed(\"shopid\", \"item\")\n",
    "df_als = df_als.withColumnRenamed(\"_c2\", \"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+\n",
      "|user| item|rating|\n",
      "+----+-----+------+\n",
      "|  72|   10|    50|\n",
      "|  72|  602|    50|\n",
      "|  72| 6649|    45|\n",
      "|  72| 6804|    50|\n",
      "|  72|11359|    45|\n",
      "|  72|13039|    50|\n",
      "|  72|13083|    50|\n",
      "| 127|   12|    25|\n",
      "| 127|  145|    30|\n",
      "| 127|  370|    15|\n",
      "| 127|  437|    30|\n",
      "| 127|  465|    30|\n",
      "| 127|  711|    25|\n",
      "| 127| 1141|    25|\n",
      "| 127| 4266|    25|\n",
      "| 127| 6554|    35|\n",
      "| 127| 6599|    35|\n",
      "| 127| 6802|    30|\n",
      "| 127| 8839|    20|\n",
      "| 127| 8844|    30|\n",
      "+----+-----+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- user: long (nullable = true)\n",
      " |-- item: long (nullable = true)\n",
      " |-- rating: long (nullable = true)\n",
      "\n",
      "+----+-----+------+\n",
      "|user| item|rating|\n",
      "+----+-----+------+\n",
      "| 127|  144|    25|\n",
      "| 127|  154|    25|\n",
      "| 127|  316|    30|\n",
      "| 127| 6564|    25|\n",
      "| 127| 6794|    25|\n",
      "| 127|10862|    35|\n",
      "| 127|11179|    40|\n",
      "| 127|11183|    40|\n",
      "| 127|11265|    35|\n",
      "| 127|11438|    20|\n",
      "| 127|13026|    45|\n",
      "| 130|  106|    30|\n",
      "| 130|  344|    35|\n",
      "| 130|  426|    30|\n",
      "| 130|  995|    35|\n",
      "| 130| 1478|    35|\n",
      "| 130| 2077|    35|\n",
      "| 130| 4281|    40|\n",
      "| 130| 4285|    35|\n",
      "| 130| 4370|    35|\n",
      "+----+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ratings = spark.createDataFrame(ratingsRDD)\n",
    "(training, test) = df_als.randomSplit([0.8, 0.2])\n",
    "\n",
    "training.show()\n",
    "training.printSchema()\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 latent factors and regularization = 0.01: validation RMSE is 31.925829609905996\n",
      "5 latent factors and regularization = 0.05: validation RMSE is 23.216537293873476\n",
      "5 latent factors and regularization = 0.1: validation RMSE is 19.691359733601253\n",
      "10 latent factors and regularization = 0.01: validation RMSE is 28.423782941161836\n",
      "10 latent factors and regularization = 0.05: validation RMSE is 19.863575127992437\n",
      "10 latent factors and regularization = 0.1: validation RMSE is 18.249207802594352\n",
      "15 latent factors and regularization = 0.01: validation RMSE is 27.535232571414426\n",
      "15 latent factors and regularization = 0.05: validation RMSE is 20.15027034131691\n",
      "15 latent factors and regularization = 0.1: validation RMSE is 18.8050550719163\n",
      "20 latent factors and regularization = 0.01: validation RMSE is 27.095376624267992\n",
      "20 latent factors and regularization = 0.05: validation RMSE is 19.01201643373598\n",
      "20 latent factors and regularization = 0.1: validation RMSE is 17.803961810123326\n",
      "\n",
      "The best model has 20 latent factors and regularization = 0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ALS_e7102f006f13"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tune_ALS(train_data, validation_data, maxIter, regParams, ranks):\n",
    "    \"\"\"\n",
    "    grid search function to select the best model based on RMSE of\n",
    "    validation data\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data: spark DF with columns ['userId', 'movieId', 'rating']\n",
    "    \n",
    "    validation_data: spark DF with columns ['userId', 'movieId', 'rating']\n",
    "    \n",
    "    maxIter: int, max number of learning iterations\n",
    "    \n",
    "    regParams: list of float, one dimension of hyper-param tuning grid\n",
    "    \n",
    "    ranks: list of float, one dimension of hyper-param tuning grid\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    The best fitted ALS model with lowest RMSE score on validation data\n",
    "    \"\"\"\n",
    "    # initial\n",
    "    min_error = float('inf')\n",
    "    best_rank = -1\n",
    "    best_regularization = 0\n",
    "    best_model = None\n",
    "    for rank in ranks:\n",
    "        for reg in regParams:\n",
    "            # get ALS model\n",
    "            als = ALS().setMaxIter(maxIter).setRank(rank).setRegParam(reg).setColdStartStrategy(\"drop\")\n",
    "            # train ALS model\n",
    "            model = als.fit(train_data)\n",
    "            # evaluate the model by computing the RMSE on the validation data\n",
    "            predictions = model.transform(validation_data)\n",
    "            evaluator = RegressionEvaluator(metricName=\"rmse\",\n",
    "                                            labelCol=\"rating\",\n",
    "                                            predictionCol=\"prediction\")\n",
    "            rmse = evaluator.evaluate(predictions)\n",
    "            print('{} latent factors and regularization = {}: '\n",
    "                  'validation RMSE is {}'.format(rank, reg, rmse))\n",
    "            if rmse < min_error:\n",
    "                min_error = rmse\n",
    "                best_rank = rank\n",
    "                best_regularization = reg\n",
    "                best_model = model\n",
    "    print('\\nThe best model has {} latent factors and '\n",
    "          'regularization = {}'.format(best_rank, best_regularization))\n",
    "    return best_model\n",
    "\n",
    "regParams = [0.01, 0.05, 0.10]\n",
    "ranks = [5, 10, 15, 20]\n",
    "tune_ALS(training, test, 20, regParams, ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 17.191200109985733\n"
     ]
    }
   ],
   "source": [
    "# Build the recommendation model using ALS on the training data\n",
    "als = ALS(maxIter=20, regParam=0.2, userCol=\"user\", itemCol=\"item\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "model = als.fit(training)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALSModel\n",
    "model_path = \"/home/vovo/PycharmProjects/etl/als.model\"\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = ALSModel.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "| user|     recommendations|\n",
      "+-----+--------------------+\n",
      "| 1580|[[11178, 53.63652...|\n",
      "| 2866|[[6691, 44.9588],...|\n",
      "| 7982|[[11299, 51.91744...|\n",
      "| 8389|[[24365, 41.18277...|\n",
      "| 8592|[[30871, 40.19397...|\n",
      "|  897|[[30310, 44.32952...|\n",
      "| 1127|[[11255, 47.65014...|\n",
      "| 1483|[[15366, 47.28492...|\n",
      "| 7417|[[30843, 43.34922...|\n",
      "| 8105|[[7241, 49.937042...|\n",
      "| 9564|[[30856, 40.99270...|\n",
      "|14514|[[31237, 35.05945...|\n",
      "| 1618|[[11210, 51.53941...|\n",
      "| 1650|[[25252, 46.13425...|\n",
      "| 4391|[[13717, 51.7347]...|\n",
      "|13009|[[25252, 55.19248...|\n",
      "|14324|[[30871, 42.96401...|\n",
      "| 7066|[[7484, 50.00861]...|\n",
      "| 8743|[[11560, 37.27383...|\n",
      "| 1977|[[169, 44.959526]...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----+--------------------+\n",
      "| item|     recommendations|\n",
      "+-----+--------------------+\n",
      "| 2142|[[9330, 38.6661],...|\n",
      "|10817|[[8722, 39.948864...|\n",
      "|11317|[[1389, 50.011253...|\n",
      "|15447|[[14438, 53.68940...|\n",
      "|15727|[[9330, 56.66809]...|\n",
      "|15957|[[9330, 45.11045]...|\n",
      "| 6620|[[14948, 42.73266...|\n",
      "|14570|[[4689, 34.957466...|\n",
      "|  471|[[1389, 45.010128...|\n",
      "|16861|[[8156, 45.78566]...|\n",
      "|18051|[[13432, 32.46340...|\n",
      "| 4519|[[9330, 51.554806...|\n",
      "|19079|[[1364, 40.141598...|\n",
      "|28146|[[14438, 63.04023...|\n",
      "|28759|[[7804, 16.243744...|\n",
      "|28836|[[10378, 41.74455...|\n",
      "|  463|[[5342, 36.6251],...|\n",
      "|17753|[[1274, 15.638256...|\n",
      "|18024|[[7804, 27.072906...|\n",
      "|28024|[[9731, 31.433723...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = model2.recommendForAllUsers(10)\n",
    "userRecs.show()\n",
    "# Generate top 10 user recommendations for each movie\n",
    "movieRecs = model2.recommendForAllItems(10)\n",
    "movieRecs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|user|\n",
      "+----+\n",
      "|8440|\n",
      "+----+\n",
      "\n",
      "+----+-----------------------------------------------------------------------------------------------+\n",
      "|user|                                                                                recommendations|\n",
      "+----+-----------------------------------------------------------------------------------------------+\n",
      "|8440|[[11560, 50.148895], [104, 49.805298], [15460, 48.047596], [30851, 46.856632], [30843, 46.02...|\n",
      "+----+-----------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate top 5 item recommendations for a specified set of 3 users\n",
    "users = df_als.select(als.getUserCol()).distinct().limit(1)\n",
    "users.show()\n",
    "userSubsetRecs = model2.recommendForUserSubset(users, 5)\n",
    "userSubsetRecs.show(truncate=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------------------------------------------------------------------------------------+\n",
      "|item|                                                                                 recommendations|\n",
      "+----+------------------------------------------------------------------------------------------------+\n",
      "|1697|[[2200, 35.358807], [3753, 34.948406], [11618, 31.129406], [1164, 29.790989], [2241, 25.592052]]|\n",
      "|2453|   [[14438, 33.78289], [7804, 33.2455], [1564, 31.899134], [4793, 31.73844], [16573, 30.532589]]|\n",
      "+----+------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate top 10 user recommendations for a specified set of 3 items\n",
    "items = df_als.select(als.getItemCol()).distinct().limit(3)\n",
    "itemSubSetRecs = model2.recommendForItemSubset(items, 5)\n",
    "itemSubSetRecs.show(truncate=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
